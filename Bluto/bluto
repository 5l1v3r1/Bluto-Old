#!/usr/local/bin/python

from multiprocessing.dummy import Pool as ThreadPool 
import dns.resolver, dns.query, dns.zone
import sys, time, datetime, socket, os, math
from termcolor import colored
import requests, re, collections, threading, Queue
from bs4 import BeautifulSoup
import urllib2, hashlib, json, site, random, string

email_address = []
targets = []
prox = True
default_s = False
myResolver = dns.resolver.Resolver()
myResolver.nameservers = ['8.8.8.8']
version = "1.1.10"

sites = site.getsitepackages()
for item in sites:
    if os.path.exists(item + "/Bluto/doc/subdomains-top1mil-20000.txt"):
        path = item
    else:
        pass

filename1 = path + "/Bluto/doc/subdomains-top1mil-20000.txt"
#filename1 = path + "/Bluto/doc/subdomains-top1mil.txt"
filename2 = path + "/Bluto/doc/sub_interest.txt"
useragent_f = path + "/Bluto/doc/user_agents.txt"
countries_file = path + "/Bluto/doc/countries.txt"

def output_data(target_dict, sub_intrest):
    temp1 = [item.lower() for item in email_address]
    new_list = sorted(set(temp1))    
    temp = 0
    for item in new_list:
        if item == '@' + domain or item == '@':
            pass
        else:
            temp += 1
            print item
    print '\nPotential Emails Found: {}' .format(str(temp))    
    sorted_dict = collections.OrderedDict(sorted(target_dict.items()))
    print "\nBluto Results: \n"
    for item in sorted_dict:
        if item in sub_intrest:
            print colored(item + "\t", 'red'), colored(sorted_dict[item], 'red')
        else:
            print item + "\t",sorted_dict[item]

    
    print "\nEmail Enumeration:", str(datetime.timedelta(seconds=(time_spent_email))) + " seconds"   
    print "Requests executed:", str(check_count) + " in " + str(datetime.timedelta(seconds=(time_spent_brute))) + " seconds"
    print "Total Time:", str(datetime.timedelta(seconds=(time_spent_total))) + " seconds\n"
                
def zone_trans(zn_list, domain):
    print "\nAttempting Zone Transfers"
    zn_list.sort()
    vuln = True
    vulnerable_listT = []
    vulnerable_listF = []
    dump_list = []
    for ns in zn_list:
        try:
            z = dns.zone.from_xfr(dns.query.xfr(ns, domain))
            names = z.nodes.keys()
            names.sort()
            if vuln == True:
                vulnerable_listT.append(ns)
                            
        except Exception as e:
            error = str(e)
            if error == "[Errno 54] Connection reset by peer" or "No answer or RRset not for qname":
                vuln = False
                vulnerable_listF.append(ns)
            else:
                print """An unexpected error has occured. Please report the error and it's context to https://github.com/RandomStorm/Bluto/issues, thank you."""
                print error          
                
    
    if vulnerable_listF:
        print "\nNot Vulnerable:\n"
        for ns in vulnerable_listF:
            print colored(ns, 'green')
    
    if vulnerable_listT:
        print "\nVulnerable:\n"
        for ns in vulnerable_listT:
            print colored(ns,'red'), colored("\t" + "TCP/53", 'red')

   
        z = dns.zone.from_xfr(dns.query.xfr(vulnerable_listT[0], domain))
        names = z.nodes.keys()
        names.sort()
        print "\nRaw Zone Dump\n"
        for n in names:
            data1 = "{}.{}" .format(n,domain)
            try:
                addr = socket.gethostbyname(data1)
                dump_list.append("{}.{} {}" .format(n, domain, addr))
            
            except Exception as e:
                error = str(e)
                if error == "[Errno -5] No address associated with hostname":
                    pass
                else:
                    print """An unexpected error has occured. Please report the error and it's context to https://github.com/RandomStorm/Bluto/issues, thank you."""
                    print error + ': in "zone_trans"\n'
            print z[n].to_text(n)

        clean_dump = sorted(set(dump_list))
        target_dict = dict((x.split(' ') for x in clean_dump))
        clean_target = collections.OrderedDict(sorted(target_dict.items()))
        print "\nProcessed Dump\n"
        for item in clean_target:
            if item in sub_intrest:
                print colored(item, 'red'), colored("\t" + clean_target[item], 'red')
            else:
                print item, "\t" + target_dict[item]
    
    
    return vulnerable_listT

def get_details(domain):
    ns_list = []
    zn_list =[]
    mx_list = []        
    try:
        print "\nName Server:\n"
        myAnswers = myResolver.query(domain, "NS")
        for data in myAnswers.rrset:
            data1 = str(data)
            data2 = (data1.rstrip('.'))
            addr = socket.gethostbyname(data2)
            ns_list.append(data2 + '\t' + addr)
            zn_list.append(data2)
            list(set(ns_list))
            ns_list.sort()
        for i in ns_list:
            print colored(i, 'green')
    except:
        e = str(sys.exc_info()[0])
        print "\nCheck The Target Domain Is Correct!\n\nQuitting.."
        sys.exit()
        
    try:    
        print "\nMail Server:\n"
        myAnswers = myResolver.query(domain, "MX")
        for data in myAnswers:
            data1 = str(data)
            data2 = (data1.split(' ',1)[1].rstrip('.'))
            addr = socket.gethostbyname(data2)
            mx_list.append(data2 + '\t' + addr)
            list(set(mx_list))
            mx_list.sort()
        for i in mx_list:
            print colored(i, 'green')
    except:
        e = str(sys.exc_info()[0])
        print "\tNo Mail Servers"   
             
    return zn_list

def line_count(filename):
    lines = 0
    for line in open(filename):
        lines += 1
    return lines

def wildCards(domain):
    try:
        one = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(15))
        myAnswers = myResolver.query(str(one) + '.' + str(domain))
    
    except dns.resolver.NXDOMAIN:
        return False
    else:
        return True    

def get_brutes(subdomain):
    try:   
        myAnswers = myResolver.query(subdomain)
        for data in myAnswers:
            targets.append(subdomain + ' ' + str(data))
            
    except Exception as e:
        pass
    
def get_subs(filename):
    full_list = []
    try:    
        subs = [line.rstrip('\n') for line in open(filename)]
        for sub in subs:
            full_list.append(str(sub.lower() + "." + domain))
    except Exception as e:
        error = str(e)
        print """An unexpected error has occured. Please report the error and it's context to https://github.com/RandomStorm/Bluto/issues, thank you."""
        print error + ': in "get_subs"\n'
        sys.exit()
        
    return full_list    
        
def get_sub_interest(filename):
    full_list = []
    try:
        subs = [line.rstrip('\n') for line in open(filename)]
        for sub in subs:
            full_list.append(str(sub.lower() + "." + domain))
    
    except Exception as e:
        error = str(e)
        print """An unexpected error has occured. Please report the error and it's context to https://github.com/RandomStorm/Bluto/issues, thank you."""
        print error + ': in "get_sub_interest"\n'
        sys.exit()
        
    return full_list


def get_netcraft(domain):
    netcraft_list = []
    print "\nPassive Gatherings From NetCraft\n"
    try:
        res = NetcraftAPI({'verbose': True}).search(domain)
    except Exception as e:
        print e
        sys.exit()
    
    for item in res:
        data1 = str(item + "." + domain)
        try:
            addr = socket.gethostbyname(data1)
            netcraft_list.append(item + "." + domain + " " + addr)
        except Exception as e:
            error = str(e)
            print """An unexpected error has occured. Please report the error and it's context to https://github.com/RandomStorm/Bluto/issues, thank you."""
            print error
            continue
            
    netcraft_list.sort()
        
    for item in netcraft_list:
            print colored(item, 'red')
            
    return netcraft_list

def LoadUserAgents(useragent_f):
    uas = []
    with open(useragent_f, 'rb') as uaf:
        for ua in uaf.readlines():
            if ua:
                uas.append(ua.strip()[1:-1-1])
    random.shuffle(uas)
    return uas

def get_gserver():
    userCountry = ''
    userServer = ''
    userIP = ''
    userID = False
    o = 0    
    tcountries_dic = {}
    country_list = []
    
    with open(countries_file) as fin:
        for line in fin:
            key, value = line.strip().split(';')
            tcountries_dic.update({key: value})
    
    countries_dic = dict((k.lower(), v.lower()) for k,v in tcountries_dic.iteritems())

    for country, server in countries_dic.items():
        country_list.append(country)
    
    country_list = [item.capitalize() for item in country_list]
    country_list.sort()
    
    while True:
        try:
            if prox == True:
                proxy = {'http' : 'http://127.0.0.1:8080'}
                r = requests.get(r'http://www.telize.com/geoip/', proxies=proxy)
                ip = r.json()['ip']
                originCountry = r.json()['country'] 
                
            else:  
                r = requests.get(r'http://www.telize.com/geoip/')
                ip = r.json()['ip']
                originCountry = r.json()['country']
                
        except ValueError as e:
            if o == 0:
                print colored('\nUnable to connect to the CountryID, we will retry.', 'red')
            if o > 0:
                print '\nThis is {} of 3 attempts' .format(o)
            time.sleep(2)
            o += 1
            if o == 4:
                break
            continue
        break
 
    if o == 4:
        print colored('\nWe have been unable to connect to the CountryID service.\n','red')
        print '\nPlease let Bluto know what country you hale from.\n'
        print colored('Available Countries:\n', 'green')
        
        if len(country_list) % 2 != 0:
            country_list.append(" ")
        
        split = len(country_list)/2
        l1 = country_list[0:split]
        l2 = country_list[split:]
        
        for key, value in zip(l1,l2):
            print "{0:<20s} {1}".format(key, value)
        
        country_list = [item.lower() for item in country_list]
        
        while True:
            originCountry = raw_input('\nCountry: ').lower()
            if originCountry in country_list:
                break
            if originCountry == '':
                print '\nYou have not selected a country so the default server will be used'
                originCountry = 'United Kingdom'.lower()
                break
            else:
                print '\nCheck your spelling and try again'
                
        for country, server in countries_dic.items():
            if country == originCountry:
                userCountry = country
                userServer = server
                userID = True
            
    else:                                   
            
        for country, server in countries_dic.items():
            if country == originCountry.lower():
                userCountry = country
                userServer = server
                userID = True      
        if userID == False:
            if default_s == True:
                userCountry = 'DEAFULT'
                pass
            else:
                print 'Bluto currently doesn\'t have your countries google server available.\nPlease navigate to "http://www.telize.com/geoip/" and post an issue to "https://github.com/RandomStorm/Bluto/issues"\nincluding the country value as shown in the json output\nYou have been assigned to http://www.google.com for now.'
                userServer = 'http://www.google.co.uk'
                userCountry = 'United Kingdom'
    
    print '\nSearching From: {0}\nGoogle Server: {1}' .format(userCountry.capitalize(), userServer)
    return (userCountry, userServer)

def googlesearch(domain, userCountry, userServer):
    i = 0
    uas = LoadUserAgents(useragent_f)
    searchfor = '@' + '"' + domain + '"'     
    for start in range(0,50):
        try:
            ua = random.choice(uas)
            if prox == True:
                proxy = {'http' : 'http://127.0.0.1:8080'}
            else:
                pass            
            headers = {"Connection" : "close", 
                       "User-Agent" : ua, 
                       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 
                       'Accept-Language': 'en-US,en;q=0.5',
                       'Accept-Encoding': 'gzip, deflate',
                       'Referer': 'http://www.google.com'}
            payload = { 'nord':'1', 'q': searchfor, 'start': start*2}

            link = '{0}/search?num=100' .format(userServer)
            if prox == True:
                response = requests.get(link, headers=headers, params=payload, proxies=proxy)
            else:
                response = requests.get(link, headers=headers, params=payload)            
            if str(response.status_code) == '503':
                if i == 0:
                    print colored('\nGoogle is responding with a Captcha...try again shortly\n', 'red')
                    print colored('Bing results will still follow\n','green')
                    i += 1
            reg_emails = re.compile('[a-zA-Z0-9.]*' + '@' + '<em>')        
            temp = reg_emails.findall(response.text)
            time.sleep(3)
            for item in temp:
                clean = item.replace("u'", "").replace('<em>','')
                email_address.append(clean + domain)
                            
        except Exception as e:
            print e
            continue

def bingsearch(domain):
    uas = LoadUserAgents(useragent_f)
    searchfor = '@' + '"' + domain + '"'  
    for start in range(0,200):
        ua = random.choice(uas)
        if prox == True:
            proxy = {'http' : 'http://127.0.0.1:8080'}
        else:
            pass
        try:
            headers = {"Connection" : "close", 
                       "User-Agent" : ua,
                       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 
                       'Accept-Language': 'en-US,en;q=0.5',
                       'Accept-Encoding': 'gzip, deflate'}
            payload = { 'q': searchfor, 'first': start}
            link = 'http://www.bing.com/search'
            if prox == True:
                response = requests.get(link, headers=headers, params=payload, proxies=proxy)
            else:
                response = requests.get(link, headers=headers, params=payload)
            reg_emails = re.compile('[a-zA-Z0-9.-]*' + '@' + '<strong>')
            temp = reg_emails.findall(response.text)
            time.sleep(1)
            for item in temp:
                clean = item.replace("<strong>", "")
                email_address.append(clean + domain)              
        except Exception as e:
            continue         

class NetcraftAPI(object):
    """
    This is the (unofficial) Python API for the netcraft.com Website.
    Using this code, you can retrieve subdomains. This has been modified from its 
    original state by the authors of Bluto, the original can be found on the following url. 
    https://github.com/PaulSec/API-netcraft.com
    
    """    

    """
        NetcraftAPI Main Handler
    """

    _instance = None
    _verbose = False

    def __init__(self, arg=None):
        pass

    def __new__(cls, *args, **kwargs):
        """
            __new__ builtin
        """
        if not cls._instance:
            cls._instance = super(NetcraftAPI, cls).__new__(
                cls, *args, **kwargs)
            if (args and args[0] and args[0]['verbose']):
                cls._verbose = True
        return cls._instance

    def display_message(self, s):
        if (self._verbose):
            print '%s' % s

    def search(self, domain):
        res = []
        url = "http://searchdns.netcraft.com/?restriction=site+contains&host=*.%s&lookup=wait..&position=limited" % domain
        s = requests.session()
        s.get('http://searchdns.netcraft.com/')
        req = s.get(url)

        challenge_cookie = req.headers['set-cookie'].split('=')[1].split(';')[0]
        string = urllib2.unquote(challenge_cookie)
        challenge_cookie_value = hashlib.sha1(string).hexdigest()
        cookies = {'netcraft_js_verification_response': challenge_cookie_value}

        req = s.get(url, cookies = cookies)
        soup = BeautifulSoup(req.content, "lxml")

        pattern = 'Found (\d+) site'
        number_results = re.findall(pattern, req.content)

        if (len(number_results) > 0 and number_results[0] != '0'):
            number_results = int(number_results[0])
            number_pages = int(math.ceil(number_results / 20)) + 1

            pattern = 'rel="nofollow">([a-z\.\-A-Z0-9]+)<FONT COLOR="#ff0000">'
            subdomains = re.findall(pattern, req.content)
            res.extend(subdomains)
            last_result = subdomains[-1]
            # "Last result: %s" % last_result

            for index_page in xrange(1, number_pages):
                url = "http://searchdns.netcraft.com/?host=*.%s&last=%s.%s&from=%s&restriction=site contains&position=limited" % (domain, last_result, domain, (index_page * 20 + 1))
                req = s.get(url, cookies = cookies)
                pattern = 'rel="nofollow">([a-z\-\.A-Z0-9]+)<FONT COLOR="#ff0000">'
                subdomains = re.findall(pattern, req.content)
                # print req.content
                res.extend(subdomains)
                try:
                    for subdomain in subdomains:
                        hostname = ('{}.{}' .format (subdomain, domain))
                        addr = socket.gethostbyname(hostname)                    
                        #self.display_message('{}.{} {}' .format (subdomain, domain, addr))
                except Exception as e:
                    pass
                last_result = subdomains[-1]
            return res
        else:
            self.display_message("\tNo results found for %s" % domain)
            return res



print """
BBBBBBBBBBBBBBBBB  lllllll                       tttt                          
B::::::::::::::::B l:::::l                     ttt:::t                          
B::::::BBBBBB:::::Bl:::::l                     t:::::t                          
BB:::::B     B:::::l:::::l{6}              t:::::t                          
  B::::B     B:::::Bl::::luuuuuu    uuuuuttttttt:::::ttttttt      ooooooooooo   
  B::::B     B:::::Bl::::lu::::u    u::::t:::::::::::::::::t    oo:::::::::::oo 
  B::::BBBBBB:::::B l::::lu::::u    u::::t:::::::::::::::::t   o:::::::::::::::o
  B:::::::::::::BB  l::::lu::::u    u::::tttttt:::::::tttttt   o:::::ooooo:::::o
  B::::BBBBBB:::::B l::::lu::::u    u::::u     t:::::t         o::::o     o::::o
  B::::B     B:::::Bl::::lu::::u    u::::u     t:::::t         o::::o     o::::o
  B::::B     B:::::Bl::::lu::::u    u::::u     t:::::t         o::::o     o::::o
  B::::B     B:::::Bl::::lu:::::uuuu:::::u     t:::::t    ttttto::::o     o::::o
BB:::::BBBBBB::::::l::::::u:::::::::::::::uu   t::::::tttt:::::o:::::ooooo:::::o
B:::::::::::::::::Bl::::::lu:::::::::::::::u   tt::::::::::::::o:::::::::::::::o
B::::::::::::::::B l::::::l uu::::::::uu:::u     tt:::::::::::ttoo:::::::::::oo 
BBBBBBBBBBBBBBBBB  llllllll   uuuuuuuu  uuuu       ttttttttttt    ooooooooooo
                                                                            
     {2} | {3} | {4} | {7}
            {0}  |  {1}
                 {5}
""" . format (colored("Author: Darryl Lane", 'blue'),colored("Twitter: @darryllane101", 'blue'),colored("DNS Recon", 'green'),colored("Brute Forcer", 'green'),colored("DNS Zone Transfers", 'green'),colored("https://github.com/RandomStorm/Bluto", 'green'),colored("v" + version, 'red'),(colored("Email Enumeration", 'green')))

domain = raw_input("\nTarget Domain: ")

if __name__ == "__main__":
#Detail Call
    sub_intrest = get_sub_interest(filename2)
    zn_list = get_details(domain)
#NetCraft Call
    netcraft_list = get_netcraft(domain)
#ZoneTrans Call    
    vulnerable_list = zone_trans(zn_list, domain)
    if vulnerable_list == []:
        print "\nNone of the Name Servers are vulnerable to Zone Transfers"
#Bruting
        print '\nTesting For Wild Cards'
        value = wildCards(domain)
        if value == True:
            print colored('\nWild Cards Are In Place','green')
            print '\nGathering Email Addresses'
            userCountry, userServer = get_gserver()
            start_time_email = time.time()
            t1 = threading.Thread(target=googlesearch, args=(domain, userCountry, userServer,))
            t2 = threading.Thread(target=bingsearch, args=(domain,))
            t1.start()
            t2.start()
            t1.join()
            t2.join()
            temp1 = [item.lower() for item in email_address]
            new_list = sorted(set(temp1))
            print '\nEmails Gathered From Google and Bing:\n'
            temp = 0
            for item in new_list:
                if item == '@' + domain or item == '@':
                    pass
                else:
                    temp += 1
                    print item
            print '\nPotential Emails Found: {}' .format(str(temp))
            time_spent_email = time.time() - start_time_email
            print "Email Enumeration:", str(datetime.timedelta(seconds=(time_spent_email))) + " seconds"            
            sys.exit()
        else:
            print colored('\nWild Cards Are Not In Place','red')
            
            check_count = line_count(filename1)
            subs = get_subs(filename1)
            pool = ThreadPool(12)
            print """
Brute Forcing Sub-Domains
    
    While you are waiting we will gather email addresses."""
        
            print '\nGathering Email Addresses From Google and Bing'
            userCountry, userServer = get_gserver()
            start_time_email = time.time()
            start_time_total = time.time()
            t1 = threading.Thread(target=googlesearch, args=(domain, userCountry, userServer,))
            t1.start()
            t2 = threading.Thread(target=bingsearch, args=(domain,))
            t2.start()
            t1.join()
            t2.join()
            time_spent_email = time.time() - start_time_email    
            start_time_brute = time.time()
            pool.map(get_brutes, subs)
            pool.close()
            time_spent_total = time.time() - start_time_total
            time_spent_brute = time.time() - start_time_brute
            if targets == []:
                targets.append("temp-enter")
            
            domains = list(set(targets + netcraft_list))
            domains.sort()
            if "temp-enter" in domains: domains.remove("temp-enter")
            target_dict = dict((x.split(' ') for x in domains))
    #Outputing data
            output_data(target_dict, sub_intrest)
    else:
        print '\nGathering Email Addresses From Google and Bing'
        t1 = threading.Thread(target=googlesearch, args=(domain,))
        t1.start()
        t2 = threading.Thread(target=bingsearch, args=(domain,))
        t2.start()
        temp1 = [item.lower() for item in email_address]
        new_list = sorted(set(temp1))
        print '\nEmails Gathered From Google and Bing:\n'
        temp = 0
        for item in new_list:
            if item == '@' + domain or item == '@':
                pass
            else:
                temp += 1
                print item
        print '\nPotential Emails Found: {}' .format(str(temp))
        time_spent_email = time.time() - start_time_email
        print "\nEmail Enumeration:", str(datetime.timedelta(seconds=(time_spent_email))) + " seconds"  
        print "\nBrute Requests Executed:", str(check_count) + " in " + str(datetime.timedelta(seconds=(time_spent_brute))) + " seconds"
        time_spent_total = time.time() - start_time_total
        print "\nTotal Time:", str(datetime.timedelta(seconds=(time_spent))) + " seconds"           